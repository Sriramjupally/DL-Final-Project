{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":73111,"databundleVersionId":8040143,"sourceType":"competition"},{"sourceId":172479726,"sourceType":"kernelVersion"}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import datasets, transforms, models\n# import torchvision.models as models\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:51:45.764954Z","iopub.execute_input":"2024-04-17T15:51:45.765519Z","iopub.status.idle":"2024-04-17T15:51:52.850109Z","shell.execute_reply.started":"2024-04-17T15:51:45.765491Z","shell.execute_reply":"2024-04-17T15:51:52.849152Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:51:56.533239Z","iopub.execute_input":"2024-04-17T15:51:56.534327Z","iopub.status.idle":"2024-04-17T15:51:56.580260Z","shell.execute_reply.started":"2024-04-17T15:51:56.534293Z","shell.execute_reply":"2024-04-17T15:51:56.579099Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((64, 64)),  \n    transforms.ToTensor(),  \n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:52:01.226307Z","iopub.execute_input":"2024-04-17T15:52:01.226942Z","iopub.status.idle":"2024-04-17T15:52:01.232823Z","shell.execute_reply.started":"2024-04-17T15:52:01.226907Z","shell.execute_reply":"2024-04-17T15:52:01.231800Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\nmodel = models.convnext_tiny(weights= None)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:52:03.600456Z","iopub.execute_input":"2024-04-17T15:52:03.600859Z","iopub.status.idle":"2024-04-17T15:52:04.296579Z","shell.execute_reply.started":"2024-04-17T15:52:03.600813Z","shell.execute_reply":"2024-04-17T15:52:04.295747Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# print(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.classifier[2] = nn.Linear(768,50)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:52:08.365689Z","iopub.execute_input":"2024-04-17T15:52:08.366051Z","iopub.status.idle":"2024-04-17T15:52:08.371086Z","shell.execute_reply.started":"2024-04-17T15:52:08.366016Z","shell.execute_reply":"2024-04-17T15:52:08.370149Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torchinfo\n\ntorchinfo.summary(model, (32, 3,64,64))","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:52:13.112710Z","iopub.execute_input":"2024-04-17T15:52:13.113624Z","iopub.status.idle":"2024-04-17T15:52:14.182546Z","shell.execute_reply.started":"2024-04-17T15:52:13.113591Z","shell.execute_reply":"2024-04-17T15:52:14.181413Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"===============================================================================================\nLayer (type:depth-idx)                        Output Shape              Param #\n===============================================================================================\nConvNeXt                                      [32, 50]                  --\n├─Sequential: 1-1                             [32, 768, 2, 2]           --\n│    └─Conv2dNormActivation: 2-1              [32, 96, 16, 16]          --\n│    │    └─Conv2d: 3-1                       [32, 96, 16, 16]          4,704\n│    │    └─LayerNorm2d: 3-2                  [32, 96, 16, 16]          192\n│    └─Sequential: 2-2                        [32, 96, 16, 16]          --\n│    │    └─CNBlock: 3-3                      [32, 96, 16, 16]          79,296\n│    │    └─CNBlock: 3-4                      [32, 96, 16, 16]          79,296\n│    │    └─CNBlock: 3-5                      [32, 96, 16, 16]          79,296\n│    └─Sequential: 2-3                        [32, 192, 8, 8]           --\n│    │    └─LayerNorm2d: 3-6                  [32, 96, 16, 16]          192\n│    │    └─Conv2d: 3-7                       [32, 192, 8, 8]           73,920\n│    └─Sequential: 2-4                        [32, 192, 8, 8]           --\n│    │    └─CNBlock: 3-8                      [32, 192, 8, 8]           306,048\n│    │    └─CNBlock: 3-9                      [32, 192, 8, 8]           306,048\n│    │    └─CNBlock: 3-10                     [32, 192, 8, 8]           306,048\n│    └─Sequential: 2-5                        [32, 384, 4, 4]           --\n│    │    └─LayerNorm2d: 3-11                 [32, 192, 8, 8]           384\n│    │    └─Conv2d: 3-12                      [32, 384, 4, 4]           295,296\n│    └─Sequential: 2-6                        [32, 384, 4, 4]           --\n│    │    └─CNBlock: 3-13                     [32, 384, 4, 4]           1,201,920\n│    │    └─CNBlock: 3-14                     [32, 384, 4, 4]           1,201,920\n│    │    └─CNBlock: 3-15                     [32, 384, 4, 4]           1,201,920\n│    │    └─CNBlock: 3-16                     [32, 384, 4, 4]           1,201,920\n│    │    └─CNBlock: 3-17                     [32, 384, 4, 4]           1,201,920\n│    │    └─CNBlock: 3-18                     [32, 384, 4, 4]           1,201,920\n│    │    └─CNBlock: 3-19                     [32, 384, 4, 4]           1,201,920\n│    │    └─CNBlock: 3-20                     [32, 384, 4, 4]           1,201,920\n│    │    └─CNBlock: 3-21                     [32, 384, 4, 4]           1,201,920\n│    └─Sequential: 2-7                        [32, 768, 2, 2]           --\n│    │    └─LayerNorm2d: 3-22                 [32, 384, 4, 4]           768\n│    │    └─Conv2d: 3-23                      [32, 768, 2, 2]           1,180,416\n│    └─Sequential: 2-8                        [32, 768, 2, 2]           --\n│    │    └─CNBlock: 3-24                     [32, 768, 2, 2]           4,763,136\n│    │    └─CNBlock: 3-25                     [32, 768, 2, 2]           4,763,136\n│    │    └─CNBlock: 3-26                     [32, 768, 2, 2]           4,763,136\n├─AdaptiveAvgPool2d: 1-2                      [32, 768, 1, 1]           --\n├─Sequential: 1-3                             [32, 50]                  --\n│    └─LayerNorm2d: 2-9                       [32, 768, 1, 1]           1,536\n│    └─Flatten: 2-10                          [32, 768]                 --\n│    └─Linear: 2-11                           [32, 50]                  38,450\n===============================================================================================\nTotal params: 27,858,578\nTrainable params: 27,858,578\nNon-trainable params: 0\nTotal mult-adds (G): 1.60\n===============================================================================================\nInput size (MB): 1.57\nForward/backward pass size (MB): 343.09\nParams size (MB): 111.41\nEstimated Total Size (MB): 456.07\n==============================================================================================="},"metadata":{}}]},{"cell_type":"code","source":"# model = CNN(num_classes=50).to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/iith-dl-contest-2024/train/train'\ntrain_data  = datasets.ImageFolder(train_dir, transform = transform)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:52:28.312458Z","iopub.execute_input":"2024-04-17T15:52:28.313104Z","iopub.status.idle":"2024-04-17T15:52:48.992569Z","shell.execute_reply.started":"2024-04-17T15:52:28.313069Z","shell.execute_reply":"2024-04-17T15:52:48.991761Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"/kaggle/input/convexnexttiny/weights10.pth\"))\n\n# # Defining loss criterion and optimizer\n# loss_func = nn.CrossEntropyLoss()\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# # Training loop\n# epochs = 16\n# for epoch in range(epochs):\n#     model.train()  # Setting the model to training mode\n#     running_loss = 0.0\n#     correct_preds = 0\n#     total_samples = 0\n#     for i, (inputs, labels) in tqdm(enumerate(train_loader)):\n#         inputs, labels = inputs.to(device), labels.to(device)\n#         optimizer.zero_grad()  # Clearing gradients\n\n#         # Forward pass\n#         outputs = model(inputs)\n\n#         # Computing loss\n#         loss = loss_func(outputs, labels)\n\n#         # Backward pass and optimization\n#         loss.backward()\n#         optimizer.step()\n\n#         # Updating running loss\n#         running_loss += loss.item() * inputs.size(0)\n\n#         # Calculating accuracy\n#         _, predicted = torch.max(outputs, 1)\n#         correct_preds += torch.sum(predicted == labels).item()\n#         total_samples += labels.size(0)\n\n#     # Printing average loss and accuracy for the current epoch\n#     epoch_loss = running_loss / len(train_data)\n#     epoch_acc = correct_preds / total_samples\n#     print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n#     if epoch%2 + 1==2:\n#         str = \"/kaggle/working/weights{}.pth\".format(epoch + 1)\n#         torch.save(model.state_dict(), str)\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:52:54.952356Z","iopub.execute_input":"2024-04-17T15:52:54.952744Z","iopub.status.idle":"2024-04-17T15:52:55.925404Z","shell.execute_reply.started":"2024-04-17T15:52:54.952712Z","shell.execute_reply":"2024-04-17T15:52:55.924332Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"test_dir = '/kaggle/input/iith-dl-contest-2024/test'\ntest_data  = datasets.ImageFolder(test_dir, transform = transform)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:53:05.259761Z","iopub.execute_input":"2024-04-17T15:53:05.260160Z","iopub.status.idle":"2024-04-17T15:53:18.523196Z","shell.execute_reply.started":"2024-04-17T15:53:05.260132Z","shell.execute_reply":"2024-04-17T15:53:18.522318Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport csv","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:53:31.491929Z","iopub.execute_input":"2024-04-17T15:53:31.492620Z","iopub.status.idle":"2024-04-17T15:53:31.496576Z","shell.execute_reply.started":"2024-04-17T15:53:31.492593Z","shell.execute_reply":"2024-04-17T15:53:31.495650Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Reverse the class to index mapping to index to class for prediction interpretation\nclasses = train_data.class_to_idx\nidx_to_class = {idx: class_name for class_name, idx in classes.items()}","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:53:38.900676Z","iopub.execute_input":"2024-04-17T15:53:38.901572Z","iopub.status.idle":"2024-04-17T15:53:38.906053Z","shell.execute_reply.started":"2024-04-17T15:53:38.901529Z","shell.execute_reply":"2024-04-17T15:53:38.904936Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# List to store outputs\noutputs_list = []\n\n# Process images and gather predictions\nfor images, _ in tqdm(test_loader):\n    images = images.to(device)\n    outputs = model(images)\n    _, predicted = torch.max(outputs, dim=1)\n    outputs_list.append(predicted)\n\n# Concatenate all predictions into a single tensor\noutputs = torch.cat(outputs_list).cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:53:42.826239Z","iopub.execute_input":"2024-04-17T15:53:42.826642Z","iopub.status.idle":"2024-04-17T15:57:56.489918Z","shell.execute_reply.started":"2024-04-17T15:53:42.826610Z","shell.execute_reply":"2024-04-17T15:57:56.489074Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 1199/1199 [04:13<00:00,  4.73it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Convert class indices to class names\npredicted_classes = np.array([idx_to_class[idx] for idx in outputs], dtype=object)\n\n# Generate image file names\nfile_names = [f\"{i}.JPEG\" for i in range(len(predicted_classes))]\n\nfile_names = np.sort(file_names)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:58:04.792506Z","iopub.execute_input":"2024-04-17T15:58:04.793306Z","iopub.status.idle":"2024-04-17T15:58:04.836058Z","shell.execute_reply.started":"2024-04-17T15:58:04.793270Z","shell.execute_reply":"2024-04-17T15:58:04.835286Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Combine file names and predicted classes\ntable = np.column_stack((file_names, predicted_classes))\n\n# Print table (optional, can be commented out in production)\nprint(table)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:58:08.045696Z","iopub.execute_input":"2024-04-17T15:58:08.046533Z","iopub.status.idle":"2024-04-17T15:58:08.054231Z","shell.execute_reply.started":"2024-04-17T15:58:08.046500Z","shell.execute_reply":"2024-04-17T15:58:08.053215Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"[['0.JPEG' 'n02808440']\n ['1.JPEG' 'n02099712']\n ['10.JPEG' 'n01944390']\n ...\n ['9997.JPEG' 'n02480495']\n ['9998.JPEG' 'n02395406']\n ['9999.JPEG' 'n01784675']]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Write results to CSV file\nwith open('submission1.csv', 'w', newline='') as file:\n    wr = csv.writer(file)\n    wr.writerow(['ID', 'Category'])\n    wr.writerows(table)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:58:11.701858Z","iopub.execute_input":"2024-04-17T15:58:11.702631Z","iopub.status.idle":"2024-04-17T15:58:11.787205Z","shell.execute_reply.started":"2024-04-17T15:58:11.702601Z","shell.execute_reply":"2024-04-17T15:58:11.786293Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# torch.save(model.state_dict(),\"/kaggle/working/model_weights_40.pth\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}