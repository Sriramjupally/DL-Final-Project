{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":73111,"databundleVersionId":8040143,"sourceType":"competition"},{"sourceId":174247101,"sourceType":"kernelVersion"},{"sourceId":174338959,"sourceType":"kernelVersion"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import datasets, transforms, models\n# import torchvision.models as models\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport numpy as np\nimport csv","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:18:43.087262Z","iopub.execute_input":"2024-04-28T18:18:43.088348Z","iopub.status.idle":"2024-04-28T18:18:43.093843Z","shell.execute_reply.started":"2024-04-28T18:18:43.088308Z","shell.execute_reply":"2024-04-28T18:18:43.092860Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:18:43.095710Z","iopub.execute_input":"2024-04-28T18:18:43.096177Z","iopub.status.idle":"2024-04-28T18:18:43.104106Z","shell.execute_reply.started":"2024-04-28T18:18:43.096141Z","shell.execute_reply":"2024-04-28T18:18:43.103207Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),  \n    transforms.ToTensor(),  \n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n])","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:18:43.105299Z","iopub.execute_input":"2024-04-28T18:18:43.105637Z","iopub.status.idle":"2024-04-28T18:18:43.112232Z","shell.execute_reply.started":"2024-04-28T18:18:43.105604Z","shell.execute_reply":"2024-04-28T18:18:43.111323Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/iith-dl-contest-2024/train/train'\ntrain_data  = datasets.ImageFolder(train_dir, transform = transform)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:18:43.113382Z","iopub.execute_input":"2024-04-28T18:18:43.113743Z","iopub.status.idle":"2024-04-28T18:18:58.565128Z","shell.execute_reply.started":"2024-04-28T18:18:43.113719Z","shell.execute_reply":"2024-04-28T18:18:58.564296Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Load pretrained Convnext_tiny\nconvnext_model = models.convnext_tiny(weights= None).to(device)\nconvnext_model.classifier[2] = nn.Linear(768,50)\nconvnext_model.load_state_dict(torch.load('/kaggle/input/cnt-weights-csv/weights15.pth', map_location=torch.device('cpu')))\nconvnext_model.to(device)\nconvnext_model.eval()  # Set to evaluation mode\n\n# Load pretrained Resnet\nresnet_model = models.resnet18(weights= None).to(device)\nresnet_model.fc = nn.Linear(512,50)\nresnet_model.load_state_dict(torch.load('/kaggle/input/resnet18-weights-csv/weights20.pth', map_location=torch.device('cpu')))\nresnet_model.to(device)\nresnet_model.eval()  # Set to evaluation mode\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:18:58.567413Z","iopub.execute_input":"2024-04-28T18:18:58.567699Z","iopub.status.idle":"2024-04-28T18:18:59.543190Z","shell.execute_reply.started":"2024-04-28T18:18:58.567674Z","shell.execute_reply":"2024-04-28T18:18:59.542201Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=50, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"class Ensemble(nn.Module):\n    def __init__(self, models):\n        super(Ensemble, self).__init__()\n        self.models = nn.ModuleList(models)  # Convert list of models to ModuleList\n\n    def forward(self, x):\n        outputs = [model(x) for model in self.models]\n        return torch.stack(outputs).mean(0)\n\n# Define the ensemble model\nensemble_model = Ensemble([resnet_model, convnext_model]).to(device)\n\n# Now ensemble_model.parameters() should contain the parameters of the models in the ensemble\n\n# Define loss criterion and optimizer for ensemble model\nloss_func = nn.CrossEntropyLoss()\noptimizer = optim.Adam(ensemble_model.parameters(), lr=0.001)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:18:59.544400Z","iopub.execute_input":"2024-04-28T18:18:59.544734Z","iopub.status.idle":"2024-04-28T18:18:59.559205Z","shell.execute_reply.started":"2024-04-28T18:18:59.544708Z","shell.execute_reply":"2024-04-28T18:18:59.558263Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dir = '/kaggle/input/iith-dl-contest-2024/test'\ntest_data  = datasets.ImageFolder(test_dir, transform = transform)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:18:59.560340Z","iopub.execute_input":"2024-04-28T18:18:59.560653Z","iopub.status.idle":"2024-04-28T18:19:12.072992Z","shell.execute_reply.started":"2024-04-28T18:18:59.560623Z","shell.execute_reply":"2024-04-28T18:19:12.072169Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport csv","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:19:12.074212Z","iopub.execute_input":"2024-04-28T18:19:12.074513Z","iopub.status.idle":"2024-04-28T18:19:12.078649Z","shell.execute_reply.started":"2024-04-28T18:19:12.074488Z","shell.execute_reply":"2024-04-28T18:19:12.077736Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Reverse the class to index mapping to index to class for prediction interpretation\nclasses = train_data.class_to_idx\nidx_to_class = {idx: class_name for class_name, idx in classes.items()}","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:19:12.080054Z","iopub.execute_input":"2024-04-28T18:19:12.080425Z","iopub.status.idle":"2024-04-28T18:19:12.087613Z","shell.execute_reply.started":"2024-04-28T18:19:12.080379Z","shell.execute_reply":"2024-04-28T18:19:12.086771Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# List to store outputs\noutputs_list = []\n\n# Process images and gather predictions\nfor images, _ in tqdm(test_loader):\n    images = images.to(device)\n    outputs = ensemble_model(images)\n    _, predicted = torch.max(outputs, dim=1)\n    outputs_list.append(predicted)\n\n# Concatenate all predictions into a single tensor\noutputs = torch.cat(outputs_list).cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:19:12.088797Z","iopub.execute_input":"2024-04-28T18:19:12.089148Z","iopub.status.idle":"2024-04-28T18:22:31.277405Z","shell.execute_reply.started":"2024-04-28T18:19:12.089116Z","shell.execute_reply":"2024-04-28T18:22:31.276678Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"100%|██████████| 1199/1199 [03:19<00:00,  6.02it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Convert class indices to class names\npredicted_classes = np.array([idx_to_class[idx] for idx in outputs], dtype=object)\n\n# Generate image file names\nfile_names = [f\"{i}.JPEG\" for i in range(len(predicted_classes))]\n\nfile_names = np.sort(file_names)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:22:31.278728Z","iopub.execute_input":"2024-04-28T18:22:31.279064Z","iopub.status.idle":"2024-04-28T18:22:31.325183Z","shell.execute_reply.started":"2024-04-28T18:22:31.279038Z","shell.execute_reply":"2024-04-28T18:22:31.324319Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Combine file names and predicted classes\ntable = np.column_stack((file_names, predicted_classes))\n\n# Print table (optional, can be commented out in production)\nprint(table)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:22:31.326336Z","iopub.execute_input":"2024-04-28T18:22:31.326618Z","iopub.status.idle":"2024-04-28T18:22:31.336034Z","shell.execute_reply.started":"2024-04-28T18:22:31.326594Z","shell.execute_reply":"2024-04-28T18:22:31.334973Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"[['0.JPEG' 'n02808440']\n ['1.JPEG' 'n02480495']\n ['10.JPEG' 'n02226429']\n ...\n ['9997.JPEG' 'n02480495']\n ['9998.JPEG' 'n02395406']\n ['9999.JPEG' 'n01774750']]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Write results to CSV file\nwith open('submissionI 111.csv', 'w', newline='') as file:\n    wr = csv.writer(file)\n    wr.writerow(['ID', 'Category'])\n    wr.writerows(table)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:22:31.337279Z","iopub.execute_input":"2024-04-28T18:22:31.337668Z","iopub.status.idle":"2024-04-28T18:22:31.433972Z","shell.execute_reply.started":"2024-04-28T18:22:31.337636Z","shell.execute_reply":"2024-04-28T18:22:31.433178Z"},"trusted":true},"execution_count":39,"outputs":[]}]}
